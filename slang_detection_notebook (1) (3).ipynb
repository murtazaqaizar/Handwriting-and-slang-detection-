{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e67e3d",
   "metadata": {},
   "source": [
    "# Slang Detection using BERT and Custom Dictionary\n",
    "\n",
    "This notebook demonstrates a process for detecting slang words within a sentence and retrieving their definitions. It utilizes a combination of:\n",
    "\n",
    "1.  **A Pre-trained BERT Model (dslim/bert-base-NER):** To analyze the sentence structure and identify potential named entities or significant tokens. While not specifically trained for slang, NER models can help isolate nouns, proper nouns, etc., which might include slang terms.\n",
    "2.  **A Custom Slang Dictionary (`slang.csv`):** Provided by the user, this file maps known slang terms to their definitions.\n",
    "\n",
    "The approach involves processing the sentence with BERT, then cross-referencing the identified tokens (reconstructed into words) with the custom slang dictionary. This allows leveraging BERT's contextual understanding while relying on the user-provided dictionary for definitive slang identification and definition retrieval.\n",
    "\n",
    "**Note:** This implementation runs on CPU. BERT inference can be slow without a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c2a40",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c533849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries (if not already installed)\n",
    "# Run this cell once if you haven't installed these libraries in your environment\n",
    "# !pip install torch transformers pandas\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import re\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a74109",
   "metadata": {},
   "source": [
    "## 2. Load Slang Dictionary\n",
    "\n",
    "This section loads the `slang.csv` file provided by the user into a Python dictionary for efficient lookup. Ensure the CSV file is in the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f29d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded slang.csv with encoding: utf-8\n",
      "Loaded 379 slang terms into dictionary.\n",
      "\n",
      "Sample slang terms loaded:\n",
      "- unfollow: To stop subscribing to someone’s social media updates\n",
      "- receipts: Proof of someone’s actions or words, often used during drama\n",
      "- shade: A subtle insult or criticism\n",
      "- troll: A person who provokes or upsets others online\n",
      "- filter: A photo effect used to enhance images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_slang_dict(filepath):\n",
    "    \"\"\"Loads the slang dictionary from a CSV file into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        # Try different encodings if default utf-8 fails\n",
    "        encodings_to_try = [\"utf-8\", \"latin1\", \"iso-8859-1\", \"cp1252\"]\n",
    "        slang_df = None\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                slang_df = pd.read_csv(filepath, encoding=encoding)\n",
    "                print(f\"Successfully loaded {os.path.basename(filepath)} with encoding: {encoding}\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "        if slang_df is None:\n",
    "            print(f\"Error: Could not decode the file {filepath} with available encodings.\")\n",
    "            return None\n",
    "\n",
    "        # Check for required columns\n",
    "        if 'term' not in slang_df.columns or 'definition' not in slang_df.columns:\n",
    "            print(f\"Error: Slang dictionary CSV at {filepath} must contain 'term' and 'definition' columns.\")\n",
    "            return None\n",
    "\n",
    "        # Clean 'term' column: strip whitespace and convert to lowercase for case-insensitive matching\n",
    "        slang_df['term'] = slang_df['term'].str.strip().str.lower()\n",
    "\n",
    "        # Optionally drop duplicates, keep first occurrence\n",
    "        slang_df = slang_df.drop_duplicates(subset=['term'], keep='first')\n",
    "\n",
    "        # Convert to dictionary\n",
    "        slang_dict = pd.Series(slang_df.definition.values, index=slang_df.term).to_dict()\n",
    "\n",
    "        print(f\"Loaded {len(slang_dict)} slang terms into dictionary.\")\n",
    "        return slang_dict\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Slang dictionary file not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the slang dictionary: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Updated Windows path (use raw string to handle backslashes)\n",
    "slang_file_path = r\"C:\\Users\\murta\\Desktop\\New folder\\Handwritten-Alphabets-Recognition\\slang.csv\"\n",
    "\n",
    "if not os.path.exists(slang_file_path):\n",
    "    print(f\"WARNING: Slang file not found at '{slang_file_path}'. Please ensure the file exists at this location or update the path. Slang detection will not work.\")\n",
    "    slang_dictionary = None\n",
    "else:\n",
    "    slang_dictionary = load_slang_dict(slang_file_path)\n",
    "\n",
    "# Display a few terms if loaded successfully\n",
    "if slang_dictionary:\n",
    "    print(\"\\nSample slang terms loaded:\")\n",
    "    count = 0\n",
    "    for term, definition in slang_dictionary.items():\n",
    "        print(f\"- {term}: {definition}\")\n",
    "        count += 1\n",
    "        if count >= 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a7da8",
   "metadata": {},
   "source": [
    "## 3. Slang Detection Function\n",
    "\n",
    "This function takes a sentence and the loaded slang dictionary as input. It uses the `dslim/bert-base-NER` model to tokenize the sentence. It then reconstructs words from tokens and checks if these words exist (case-insensitively) in the slang dictionary. If a match is found, the slang term and its definition are returned.\n",
    "\n",
    "**Note:** The BERT model is loaded outside the function for efficiency, so it's only loaded once when this cell is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dde99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_sentences_from_file(file_path):\n",
    "    \"\"\"Reads sentences from a text file (one per line).\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            sentences = [line.strip() for line in file if line.strip()]\n",
    "        print(f\"Loaded {len(sentences)} sentence(s) from {file_path}.\")\n",
    "        return sentences\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return []\n",
    "# Prompt user for a file path to read sentences from\n",
    "text_file_path = input(\"C:/Users/murta/Desktop/New folder/Handwritten-Alphabets-Recognition/text.txt\").strip()\n",
    "\n",
    "if text_file_path:\n",
    "    file_sentences = read_sentences_from_file(text_file_path)\n",
    "    if file_sentences and slang_dictionary:\n",
    "        print(\"\\n--- File-based Detection ---\")\n",
    "        for sentence in file_sentences:\n",
    "            print(f\"\\nSentence: {sentence}\")\n",
    "            result = detect_slang_bert(sentence, slang_dictionary)\n",
    "            print(result)\n",
    "            print(\"---\")\n",
    "    elif not slang_dictionary:\n",
    "        print(\"Slang dictionary not loaded. Cannot analyze file content.\")\n",
    "else:\n",
    "    print(\"No text file provided. Skipping file-based detection.\")\n",
    "\n",
    "def detect_slang_bert(sentence, slang_dictionary):\n",
    "    \"\"\"Detects slang in a sentence using BERT tokenization and a slang dictionary lookup.\"\"\"\n",
    "    if not slang_dictionary:\n",
    "        return \"Error: Slang dictionary not loaded or empty.\"\n",
    "    if not tokenizer or not model:\n",
    "        return \"Error: BERT model or tokenizer failed to load.\"\n",
    "\n",
    "    try:\n",
    "        # Get inputs for the model\n",
    "        inputs = tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            is_split_into_words=False\n",
    "        )\n",
    "\n",
    "        # Get word_ids using a separate encoding object\n",
    "        encoding = tokenizer(\n",
    "            sentence,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            is_split_into_words=False\n",
    "        )\n",
    "        word_indices = encoding.word_ids()\n",
    "\n",
    "        # Move tensor inputs to device\n",
    "        model_inputs = {k: v.to(device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "        token_ids = inputs[\"input_ids\"][0]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**model_inputs)\n",
    "\n",
    "        # Reconstruct words from subword tokens\n",
    "        found_slang = {}\n",
    "        current_word_reconstructed = \"\"\n",
    "        last_word_idx = -1\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in tokenizer.all_special_tokens:\n",
    "                continue\n",
    "\n",
    "            word_idx = word_indices[i] if i < len(word_indices) else None\n",
    "            if word_idx is None:\n",
    "                continue\n",
    "\n",
    "            if word_idx != last_word_idx and last_word_idx != -1:\n",
    "                if current_word_reconstructed.lower() in slang_dictionary:\n",
    "                    if current_word_reconstructed not in found_slang:\n",
    "                        found_slang[current_word_reconstructed] = slang_dictionary[current_word_reconstructed.lower()]\n",
    "                current_word_reconstructed = \"\"\n",
    "\n",
    "            token_part = token[2:] if token.startswith(\"##\") else token\n",
    "            current_word_reconstructed += token_part\n",
    "            last_word_idx = word_idx\n",
    "\n",
    "        if current_word_reconstructed and current_word_reconstructed.lower() in slang_dictionary:\n",
    "            if current_word_reconstructed not in found_slang:\n",
    "                found_slang[current_word_reconstructed] = slang_dictionary[current_word_reconstructed.lower()]\n",
    "\n",
    "        if not found_slang:\n",
    "            return \"No slang detected in the sentence.\"\n",
    "        else:\n",
    "            result = \"Detected Slang:\\n\"\n",
    "            for word in sorted(found_slang.keys()):\n",
    "                result += f\"- {word}: {found_slang[word]}\\n\"\n",
    "            return result.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return f\"An error occurred during slang detection: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb42eaf",
   "metadata": {},
   "source": [
    "## 4. Interactive Slang Detection\n",
    "\n",
    "Enter a sentence in the text box below and run the cell (Shift+Enter) to detect slang terms based on the loaded dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c1bda7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  Beyoncé is the GOAT. No debate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Result --\n",
      "Detected Slang:\n",
      "- GOAT: Acronym for \"Greatest Of All Time.\"\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "sentence_to_check = input(\"Enter a sentence: \")\n",
    "\n",
    "# Detect slang\n",
    "if sentence_to_check:\n",
    "    # Make sure the dictionary loaded correctly before proceeding\n",
    "    if slang_dictionary is not None:\n",
    "        detection_result = detect_slang_bert(sentence_to_check, slang_dictionary)\n",
    "        print(\"\\n-- Result --\")\n",
    "        print(detection_result)\n",
    "    else:\n",
    "        print(\"Error: Cannot detect slang because the dictionary failed to load.\")\n",
    "else:\n",
    "    print(\"Please enter a sentence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ecafd0",
   "metadata": {},
   "source": [
    "## 5. Example Sentences\n",
    "\n",
    "Here are some examples using predefined sentences to test the detection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3973cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running example sentences...\n",
      "\n",
      "Sentence: That movie was fire, totally slayed.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: He's just trolling, don't feed the troll.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: This is a normal sentence without any specific slang.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: OMG that OOTD is goals!\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: She unfollowed him after the argument.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: I’ve got the receipts to back it up.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: That fit is drip.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n",
      "\n",
      "Sentence: No cap, that was impressive.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_18020\\3864800046.py\", line 40, in detect_slang_bert\n",
      "    word_indices = inputs.word_ids(batch_index=0) # Get word indices\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "AttributeError: 'dict' object has no attribute 'word_ids'\n",
      "\n",
      "An error occurred during slang detection: 'dict' object has no attribute 'word_ids'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"That movie was fire, totally slayed.\",\n",
    "    \"He's just trolling, don't feed the troll.\",\n",
    "    \"This is a normal sentence without any specific slang.\",\n",
    "    \"OMG that OOTD is goals!\",\n",
    "    \"She unfollowed him after the argument.\",  # From slang.csv example\n",
    "    \"I’ve got the receipts to back it up.\",     # From slang.csv example\n",
    "    \"That fit is drip.\",\n",
    "    \"No cap, that was impressive.\"\n",
    "]\n",
    "\n",
    "# Make sure the dictionary loaded correctly before running examples\n",
    "if slang_dictionary is not None:\n",
    "    print(\"Running example sentences...\")\n",
    "    for sentence in test_sentences:\n",
    "        print(f\"\\nSentence: {sentence}\")\n",
    "        result = detect_slang_bert(sentence, slang_dictionary)\n",
    "        print(result)\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"Error: Cannot run examples because the slang dictionary failed to load.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec81794-dae7-4f57-9c59-4e623ebefd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
